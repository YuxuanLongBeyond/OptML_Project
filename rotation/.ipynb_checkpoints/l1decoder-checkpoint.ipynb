{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy import linalg as LA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1decode_pd(x0, A, y, pdtol, pdmaxiter):\n",
    "    '''\n",
    "        suppose we would like to solve Ax = y with y contaminated\n",
    "        this function can help to exactly recover x\n",
    "\n",
    "        x0 : the initial value for x\n",
    "        pdtol : tolerance for stopping the algorithm\n",
    "        pdmaxiter : the max iteration which is also a stopping criteria\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # shape of A matrix\n",
    "    N = x0.shape[0]  # column\n",
    "    M = y.shape[0]  # row\n",
    "\n",
    "    # backtracking parameters\n",
    "    alpha = 0.01\n",
    "    beta = 0.5\n",
    "\n",
    "    # update parameter\n",
    "    mu = 10\n",
    "\n",
    "    gradf0 = np.vstack((np.zeros((N, 1)), np.ones((M, 1))))\n",
    "\n",
    "    # initialization on primal variables x and u\n",
    "    x = x0\n",
    "    Ax = A @ x\n",
    "    u = (0.95) * abs(y - Ax) + (0.10) * max(abs(y - Ax))\n",
    "\n",
    "    # inequality constraints\n",
    "    fu1 = Ax - y - u\n",
    "    fu2 = -Ax + y - u\n",
    "\n",
    "    # dual variables initialization\n",
    "    lamu1 = -1. / fu1\n",
    "    lamu2 = -1. / fu2\n",
    "\n",
    "    # the first line of dual residual, but it's kind of strange\n",
    "    # since we dont have equality constrains here, in other words\n",
    "    # Atv does not exis\n",
    "    Atv = A.T @ (lamu1 - lamu2)\n",
    "\n",
    "    # initialize surrogate duality gap and tau\n",
    "    sdg = -(fu1.T @ lamu1 + fu2.T @ lamu2)\n",
    "    tau = mu * 2 * M / sdg  # multiply by 2 since we divide constrains into two parts\n",
    "    # we have totally 2M inequality constrains\n",
    "\n",
    "    # initialize rcent, rdual and resnorm\n",
    "    # rcent is central residual\n",
    "    # rdual is dual residual\n",
    "    # resnorm is used to check if the rdual and rcent is small enough\n",
    "    rcent = np.vstack((-lamu1 * fu1, -lamu2 * fu2)) - (1 / tau)\n",
    "    rdual = gradf0 + np.vstack((Atv, -lamu1 - lamu2))\n",
    "    resnorm = LA.norm(np.vstack((rdual, rcent)))\n",
    "\n",
    "    pditer = 0\n",
    "    done = (sdg < pdtol) | (pditer >= pdmaxiter)\n",
    "\n",
    "    while (not done):\n",
    "\n",
    "        pditer += 1\n",
    "\n",
    "        w2 = -1 - 1 / tau * (1 / fu1 + 1 / fu2)\n",
    "\n",
    "        sig1 = -lamu1 / fu1 - lamu2 / fu2\n",
    "        sig2 = lamu1 / fu1 - lamu2 / fu2\n",
    "        sigx = sig1 - sig2 ** 2 / sig1\n",
    "\n",
    "        w1 = -1 / tau * (A.T @ (-1 / fu1 + 1 / fu2))\n",
    "\n",
    "        # w1p and H11p are used to solve dx, conjugate gradients algorithm are\n",
    "        # used in the origal code, but it has been modified\n",
    "        w1p = w1 - A.T @ ((sig2 / sig1) * w2)\n",
    "        # H11p = AtDiagA(AtA,sigx)\n",
    "\n",
    "\n",
    "        sigx = sigx.squeeze()\n",
    "        H11p = A.T @ (np.diag(sigx)) @ A;\n",
    "\n",
    "        dx = np.linalg.solve(H11p, w1p)\n",
    "        Adx = A @ dx\n",
    "\n",
    "        # solve for primal variable\n",
    "        du = (w2 - sig2 * Adx) / sig1\n",
    "        # solve for dual variables\n",
    "        dlamu1 = -(lamu1 / fu1) * (Adx - du) - lamu1 - (1 / tau) * 1 / fu1\n",
    "        dlamu2 = (lamu2 / fu2) * (Adx + du) - lamu2 - (1 / tau) * 1 / fu2\n",
    "\n",
    "        #\n",
    "        Atdv = A.T @ (dlamu1 - dlamu2)\n",
    "\n",
    "        # make sure that the step is feasible: keeps lamu1,lamu2 > 0, fu1,fu2 < 0\n",
    "        indl = np.where(dlamu1 < 0);\n",
    "        indu = np.where(dlamu2 < 0);\n",
    "        #s = min([1, -lamu1[indl] / dlamu1[indl], -lamu2[indu] / dlamu2[indu]]);\n",
    "        s = min([1, min(-lamu1[indl] / dlamu1[indl]), min(-lamu2[indu] / dlamu2[indu])]);\n",
    "        indl = np.where((Adx - du) > 0);\n",
    "        indu = np.where((-Adx - du) > 0);\n",
    "        s = (0.99) * min([s, min(-fu1[indl] / (Adx[indl] - du[indl])), min(-fu2[indu] / (-Adx[indu] - du[indu]))])\n",
    "\n",
    "        # backtrack\n",
    "        suffdec = 0\n",
    "        backiter = 0\n",
    "        while (not suffdec):\n",
    "\n",
    "            # primal variables update\n",
    "            xp = x + s * dx;\n",
    "            up = u + s * du;\n",
    "            # dual variables update\n",
    "            lamu1p = lamu1 + s * dlamu1;\n",
    "            lamu2p = lamu2 + s * dlamu2;\n",
    "\n",
    "            Axp = Ax + s * Adx;\n",
    "            Atvp = Atv + s * Atdv;\n",
    "\n",
    "            fu1p = Axp - y - up;\n",
    "            fu2p = -Axp + y - up;\n",
    "\n",
    "            rdp = gradf0 + np.vstack((Atvp, -lamu1p - lamu2p))\n",
    "            rcp = np.vstack((-lamu1p * fu1p, -lamu2p * fu2p)) - (1 / tau)\n",
    "\n",
    "            suffdec = (LA.norm(np.vstack((rdp, rcp))) <= (1 - alpha * s) * resnorm)\n",
    "            s = beta * s;\n",
    "            backiter = backiter + 1;\n",
    "            if (backiter > 32):\n",
    "                print('Stuck backtracking, returning last iterate.')\n",
    "                xp = x\n",
    "                break\n",
    "\n",
    "        # next iteration\n",
    "        x = xp;\n",
    "        u = up;\n",
    "        Ax = Axp;\n",
    "        Atv = Atvp;\n",
    "        lamu1 = lamu1p;\n",
    "        lamu2 = lamu2p;\n",
    "        fu1 = fu1p;\n",
    "        fu2 = fu2p;\n",
    "\n",
    "        # surrogate duality gap\n",
    "        sdg = -(fu1.T @ lamu1 + fu2.T @ lamu2);\n",
    "        tau = mu * 2 * M / sdg;\n",
    "        rcent = np.vstack((-lamu1 * fu1, -lamu2 * fu2)) - (1 / tau)\n",
    "        rdual = rdp;\n",
    "        resnorm = LA.norm(np.vstack((rdual, rcent)))\n",
    "\n",
    "        done = (sdg < pdtol) | (pditer >= pdmaxiter);\n",
    "\n",
    "    return xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source length\n",
    "N = 25\n",
    "\n",
    "# codeword length\n",
    "M = 4*N\n",
    "\n",
    "# number of perturbations\n",
    "T = round(0.3*M)\n",
    "\n",
    "# coding matrix\n",
    "A = np.random.randn(M,N)\n",
    "# source word\n",
    "x = np.random.randn(N,1)\n",
    "\n",
    "# code word\n",
    "c = np.dot(A,x)\n",
    "\n",
    "# channel: perturb T randomly chosen entries\n",
    "q = np.random.permutation(M)\n",
    "y = c\n",
    "y[q[0:T]] = np.random.randn(T,1)\n",
    "\n",
    "# initial value for x\n",
    "x0 = inv(A.T@A)@A.T@y\n",
    "\n",
    "#x0 = pinv(G)*y\n",
    "#x0 = ones(256,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = l1decode_pd(x0, A, y, 1e-4, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.12772817]\n",
      " [ 1.94146509]\n",
      " [-0.26866417]\n",
      " [ 0.62751721]\n",
      " [-0.57932204]\n",
      " [-0.05387968]\n",
      " [ 0.42986591]\n",
      " [ 0.24241646]\n",
      " [-0.11910728]\n",
      " [ 1.24911302]\n",
      " [ 0.36462749]\n",
      " [ 0.52857129]\n",
      " [ 0.05455074]\n",
      " [ 0.22225493]\n",
      " [-0.61404262]\n",
      " [ 0.98361104]\n",
      " [ 1.50600067]\n",
      " [-0.52018027]\n",
      " [ 0.7607542 ]\n",
      " [ 1.01613512]\n",
      " [ 1.31151074]\n",
      " [-0.87965185]\n",
      " [-1.64743488]\n",
      " [ 0.65329212]\n",
      " [ 1.85286385]]\n"
     ]
    }
   ],
   "source": [
    "print(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.12772836],\n",
       "       [ 1.94146515],\n",
       "       [-0.2686641 ],\n",
       "       [ 0.62751724],\n",
       "       [-0.57932205],\n",
       "       [-0.05387968],\n",
       "       [ 0.42986594],\n",
       "       [ 0.24241641],\n",
       "       [-0.11910734],\n",
       "       [ 1.24911312],\n",
       "       [ 0.36462753],\n",
       "       [ 0.52857133],\n",
       "       [ 0.0545505 ],\n",
       "       [ 0.22225497],\n",
       "       [-0.61404277],\n",
       "       [ 0.98361084],\n",
       "       [ 1.50600081],\n",
       "       [-0.52018027],\n",
       "       [ 0.76075412],\n",
       "       [ 1.01613523],\n",
       "       [ 1.31151086],\n",
       "       [-0.8796519 ],\n",
       "       [-1.64743496],\n",
       "       [ 0.65329224],\n",
       "       [ 1.8528641 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
